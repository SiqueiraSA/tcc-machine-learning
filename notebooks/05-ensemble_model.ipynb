{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Core Packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "### Visualization Packages\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "### Machine Learning Packages\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_curve, auc, confusion_matrix\n",
    "\n",
    "### Setting env\n",
    "import os, sys\n",
    "\n",
    "folder = os.getcwd()\n",
    "if(not(folder.endswith('tcc-machine-learning'))):\n",
    "        os.chdir('..')\n",
    "folder = os.getcwd()\n",
    "\n",
    "### Functions\n",
    "from dags import config\n",
    "from dags.utils import generate_label, save_image\n",
    "\n",
    "### Others\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Average(lst):\n",
    "    return sum(lst) / len(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Guilherme\\Desktop\\Guilherme\\TCC\\tcc-machine-learning\\notebooks\\05-ensemble_model.ipynb Célula: 3\u001b[0m in \u001b[0;36m<cell line: 33>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Guilherme/Desktop/Guilherme/TCC/tcc-machine-learning/notebooks/05-ensemble_model.ipynb#X12sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m rf\u001b[39m.\u001b[39mfit(X, y)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Guilherme/Desktop/Guilherme/TCC/tcc-machine-learning/notebooks/05-ensemble_model.ipynb#X12sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m rfe \u001b[39m=\u001b[39m RFECV(rf, cv\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, scoring\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mneg_mean_squared_error\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Guilherme/Desktop/Guilherme/TCC/tcc-machine-learning/notebooks/05-ensemble_model.ipynb#X12sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m rfe\u001b[39m.\u001b[39;49mfit(X_train,y_train)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Guilherme/Desktop/Guilherme/TCC/tcc-machine-learning/notebooks/05-ensemble_model.ipynb#X12sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m selected_features \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(np\u001b[39m.\u001b[39marray(feature_names)[rfe\u001b[39m.\u001b[39mget_support()])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Guilherme/Desktop/Guilherme/TCC/tcc-machine-learning/notebooks/05-ensemble_model.ipynb#X12sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m df_selected \u001b[39m=\u001b[39m df_train[selected_features \u001b[39m+\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mtarget\u001b[39m\u001b[39m'\u001b[39m]]\n",
      "File \u001b[1;32mc:\\Users\\Guilherme\\anaconda3\\envs\\tcc-env\\lib\\site-packages\\sklearn\\feature_selection\\_rfe.py:732\u001b[0m, in \u001b[0;36mRFECV.fit\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m    723\u001b[0m \u001b[39m# Re-execute an elimination with best_k over the whole set\u001b[39;00m\n\u001b[0;32m    724\u001b[0m rfe \u001b[39m=\u001b[39m RFE(\n\u001b[0;32m    725\u001b[0m     estimator\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimator,\n\u001b[0;32m    726\u001b[0m     n_features_to_select\u001b[39m=\u001b[39mn_features_to_select,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    729\u001b[0m     verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose,\n\u001b[0;32m    730\u001b[0m )\n\u001b[1;32m--> 732\u001b[0m rfe\u001b[39m.\u001b[39;49mfit(X, y)\n\u001b[0;32m    734\u001b[0m \u001b[39m# Set final attributes\u001b[39;00m\n\u001b[0;32m    735\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msupport_ \u001b[39m=\u001b[39m rfe\u001b[39m.\u001b[39msupport_\n",
      "File \u001b[1;32mc:\\Users\\Guilherme\\anaconda3\\envs\\tcc-env\\lib\\site-packages\\sklearn\\feature_selection\\_rfe.py:222\u001b[0m, in \u001b[0;36mRFE.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params):\n\u001b[0;32m    203\u001b[0m     \u001b[39m\"\"\"Fit the RFE model and then the underlying estimator on the selected features.\u001b[39;00m\n\u001b[0;32m    204\u001b[0m \n\u001b[0;32m    205\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    220\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m    221\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 222\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n",
      "File \u001b[1;32mc:\\Users\\Guilherme\\anaconda3\\envs\\tcc-env\\lib\\site-packages\\sklearn\\feature_selection\\_rfe.py:283\u001b[0m, in \u001b[0;36mRFE._fit\u001b[1;34m(self, X, y, step_score, **fit_params)\u001b[0m\n\u001b[0;32m    280\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    281\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mFitting estimator with \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m features.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m np\u001b[39m.\u001b[39msum(support_))\n\u001b[1;32m--> 283\u001b[0m estimator\u001b[39m.\u001b[39mfit(X[:, features], y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    285\u001b[0m \u001b[39m# Get importance and rank them\u001b[39;00m\n\u001b[0;32m    286\u001b[0m importances \u001b[39m=\u001b[39m _get_feature_importances(\n\u001b[0;32m    287\u001b[0m     estimator,\n\u001b[0;32m    288\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimportance_getter,\n\u001b[0;32m    289\u001b[0m     transform_func\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msquare\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    290\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Guilherme\\anaconda3\\envs\\tcc-env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:450\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    439\u001b[0m trees \u001b[39m=\u001b[39m [\n\u001b[0;32m    440\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_estimator(append\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[0;32m    441\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    442\u001b[0m ]\n\u001b[0;32m    444\u001b[0m \u001b[39m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    445\u001b[0m \u001b[39m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    446\u001b[0m \u001b[39m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    447\u001b[0m \u001b[39m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    448\u001b[0m \u001b[39m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    449\u001b[0m \u001b[39m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 450\u001b[0m trees \u001b[39m=\u001b[39m Parallel(\n\u001b[0;32m    451\u001b[0m     n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs,\n\u001b[0;32m    452\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m    453\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m_joblib_parallel_args(prefer\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mthreads\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m    454\u001b[0m )(\n\u001b[0;32m    455\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[0;32m    456\u001b[0m         t,\n\u001b[0;32m    457\u001b[0m         \u001b[39mself\u001b[39;49m,\n\u001b[0;32m    458\u001b[0m         X,\n\u001b[0;32m    459\u001b[0m         y,\n\u001b[0;32m    460\u001b[0m         sample_weight,\n\u001b[0;32m    461\u001b[0m         i,\n\u001b[0;32m    462\u001b[0m         \u001b[39mlen\u001b[39;49m(trees),\n\u001b[0;32m    463\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m    464\u001b[0m         class_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_weight,\n\u001b[0;32m    465\u001b[0m         n_samples_bootstrap\u001b[39m=\u001b[39;49mn_samples_bootstrap,\n\u001b[0;32m    466\u001b[0m     )\n\u001b[0;32m    467\u001b[0m     \u001b[39mfor\u001b[39;49;00m i, t \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(trees)\n\u001b[0;32m    468\u001b[0m )\n\u001b[0;32m    470\u001b[0m \u001b[39m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    471\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_\u001b[39m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32mc:\\Users\\Guilherme\\anaconda3\\envs\\tcc-env\\lib\\site-packages\\joblib\\parallel.py:1056\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1053\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1055\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1056\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve()\n\u001b[0;32m   1057\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1058\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "File \u001b[1;32mc:\\Users\\Guilherme\\anaconda3\\envs\\tcc-env\\lib\\site-packages\\joblib\\parallel.py:935\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    933\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    934\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m--> 935\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout))\n\u001b[0;32m    936\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    937\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
      "File \u001b[1;32mc:\\Users\\Guilherme\\anaconda3\\envs\\tcc-env\\lib\\multiprocessing\\pool.py:765\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    764\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m--> 765\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[0;32m    766\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mready():\n\u001b[0;32m    767\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Guilherme\\anaconda3\\envs\\tcc-env\\lib\\multiprocessing\\pool.py:762\u001b[0m, in \u001b[0;36mApplyResult.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwait\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m--> 762\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_event\u001b[39m.\u001b[39;49mwait(timeout)\n",
      "File \u001b[1;32mc:\\Users\\Guilherme\\anaconda3\\envs\\tcc-env\\lib\\threading.py:574\u001b[0m, in \u001b[0;36mEvent.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    572\u001b[0m signaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flag\n\u001b[0;32m    573\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m signaled:\n\u001b[1;32m--> 574\u001b[0m     signaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cond\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[0;32m    575\u001b[0m \u001b[39mreturn\u001b[39;00m signaled\n",
      "File \u001b[1;32mc:\\Users\\Guilherme\\anaconda3\\envs\\tcc-env\\lib\\threading.py:312\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    310\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    311\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 312\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[0;32m    313\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    314\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ticker = 'petr4.sa'\n",
    "df_ticker = pd.read_csv(f'data/processed/{ticker}_processed.csv', encoding='utf8', delimiter=',')\n",
    "df_ticker['date'] = pd.to_datetime(df_ticker['date'])\n",
    "df_ticker_target = df_ticker.loc[(df_ticker['date'] >= '2015-01-01')]\n",
    "\n",
    "days = 60\n",
    "df_train = generate_label(days, df_ticker_target)\n",
    "df_train = df_train.set_index('date')\n",
    "\n",
    "transfor = 'normal'\n",
    "dir_func = np.log if transfor == 'log' else lambda x:x\n",
    "inf_func = np.exp if transfor == 'log' else lambda x:x\n",
    "\n",
    "cols_to_transform = [col for col in df_train.columns if not 'target' in col]\n",
    "df_train[cols_to_transform] = dir_func(df_train[cols_to_transform])\n",
    "\n",
    "\n",
    "X = df_train.drop(columns = 'target')\n",
    "y = df_train['target']\n",
    "feature_names = X.columns\n",
    "\n",
    "st_feat = MinMaxScaler()\n",
    "X = X.sort_index(axis = 1)\n",
    "X = st_feat.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y)\n",
    "\n",
    "### Feature Selection\n",
    "rf = RandomForestClassifier(n_estimators=400, min_samples_leaf=2, oob_score=True, bootstrap=True, n_jobs=4)\n",
    "rf.fit(X, y)\n",
    "  \n",
    "rfe = RFECV(rf, cv=5, scoring=\"neg_mean_squared_error\")\n",
    "rfe.fit(X_train,y_train)\n",
    "selected_features = list(np.array(feature_names)[rfe.get_support()])\n",
    "df_selected = df_train[selected_features + ['target']]\n",
    "\n",
    "classifiers = [\n",
    "    (\"KNC\", KNeighborsClassifier(n_neighbors = 5, weights = \"distance\", p = 1)),\n",
    "    (\"SVC\", SVC(kernel= \"rbf\", gamma = 3.5, C = 1000)),\n",
    "    (\"MLP\", MLPClassifier(max_iter = 10000, activation = 'tanh', alpha = 0.0001, learning_rate = 'constant')),\n",
    "    (\"RF\", RandomForestClassifier(n_estimators=400, min_samples_leaf=2, oob_score=True, bootstrap=True, n_jobs=4)),\n",
    "    (\"ADA\", AdaBoostClassifier(n_estimators = 1000, base_estimator = DecisionTreeClassifier(max_depth=9, min_samples_leaf = 2)))\n",
    "]\n",
    "\n",
    "X = df_selected.drop(columns = 'target')\n",
    "y = df_selected['target']\n",
    "feature_names = X.columns\n",
    "\n",
    "st_feat = MinMaxScaler()\n",
    "X = X.sort_index(axis = 1)\n",
    "X = st_feat.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y)\n",
    "\n",
    "clf = StackingClassifier(estimators=classifiers, final_estimator = RandomForestClassifier(n_estimators=400, min_samples_leaf=2, oob_score=True, bootstrap=True, n_jobs=4))\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print('Acurancia Stacking', accuracy_score(y_test, clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image confusion_vale3.sa_3_3 saved.\n",
      "Image roc_vale3.sa_3_3 saved.\n",
      "Image confusion_vale3.sa_7_3 saved.\n",
      "Image roc_vale3.sa_7_3 saved.\n",
      "Image confusion_vale3.sa_15_3 saved.\n",
      "Image roc_vale3.sa_15_3 saved.\n",
      "Image confusion_vale3.sa_30_3 saved.\n",
      "Image roc_vale3.sa_30_3 saved.\n",
      "Image confusion_vale3.sa_60_3 saved.\n",
      "Image roc_vale3.sa_60_3 saved.\n",
      "Image confusion_itub4.sa_3_3 saved.\n",
      "Image roc_itub4.sa_3_3 saved.\n",
      "Image confusion_itub4.sa_7_3 saved.\n",
      "Image roc_itub4.sa_7_3 saved.\n",
      "Image confusion_itub4.sa_15_3 saved.\n",
      "Image roc_itub4.sa_15_3 saved.\n",
      "Image confusion_itub4.sa_30_3 saved.\n",
      "Image roc_itub4.sa_30_3 saved.\n",
      "Image confusion_itub4.sa_60_3 saved.\n",
      "Image roc_itub4.sa_60_3 saved.\n",
      "Image confusion_bbdc4.sa_3_3 saved.\n",
      "Image roc_bbdc4.sa_3_3 saved.\n",
      "Image confusion_bbdc4.sa_7_3 saved.\n",
      "Image roc_bbdc4.sa_7_3 saved.\n",
      "Image confusion_bbdc4.sa_15_3 saved.\n",
      "Image roc_bbdc4.sa_15_3 saved.\n",
      "Image confusion_bbdc4.sa_30_3 saved.\n",
      "Image roc_bbdc4.sa_30_3 saved.\n",
      "Image confusion_bbdc4.sa_60_3 saved.\n",
      "Image roc_bbdc4.sa_60_3 saved.\n",
      "Image confusion_petr4.sa_3_3 saved.\n",
      "Image roc_petr4.sa_3_3 saved.\n",
      "Image confusion_petr4.sa_7_3 saved.\n",
      "Image roc_petr4.sa_7_3 saved.\n",
      "Image confusion_petr4.sa_15_3 saved.\n",
      "Image roc_petr4.sa_15_3 saved.\n",
      "Image confusion_petr4.sa_30_3 saved.\n",
      "Image roc_petr4.sa_30_3 saved.\n",
      "Image confusion_petr4.sa_60_3 saved.\n",
      "Image roc_petr4.sa_60_3 saved.\n",
      "Image confusion_vale3.sa_3_4 saved.\n",
      "Image roc_vale3.sa_3_4 saved.\n",
      "Image confusion_vale3.sa_7_4 saved.\n",
      "Image roc_vale3.sa_7_4 saved.\n",
      "Image confusion_vale3.sa_15_4 saved.\n",
      "Image roc_vale3.sa_15_4 saved.\n",
      "Image confusion_vale3.sa_30_4 saved.\n",
      "Image roc_vale3.sa_30_4 saved.\n",
      "Image confusion_vale3.sa_60_4 saved.\n",
      "Image roc_vale3.sa_60_4 saved.\n",
      "Image confusion_itub4.sa_3_4 saved.\n",
      "Image roc_itub4.sa_3_4 saved.\n",
      "Image confusion_itub4.sa_7_4 saved.\n",
      "Image roc_itub4.sa_7_4 saved.\n",
      "Image confusion_itub4.sa_15_4 saved.\n",
      "Image roc_itub4.sa_15_4 saved.\n",
      "Image confusion_itub4.sa_30_4 saved.\n",
      "Image roc_itub4.sa_30_4 saved.\n",
      "Image confusion_itub4.sa_60_4 saved.\n",
      "Image roc_itub4.sa_60_4 saved.\n",
      "Image confusion_bbdc4.sa_3_4 saved.\n",
      "Image roc_bbdc4.sa_3_4 saved.\n",
      "Image confusion_bbdc4.sa_7_4 saved.\n",
      "Image roc_bbdc4.sa_7_4 saved.\n",
      "Image confusion_bbdc4.sa_15_4 saved.\n",
      "Image roc_bbdc4.sa_15_4 saved.\n",
      "Image confusion_bbdc4.sa_30_4 saved.\n",
      "Image roc_bbdc4.sa_30_4 saved.\n",
      "Image confusion_bbdc4.sa_60_4 saved.\n",
      "Image roc_bbdc4.sa_60_4 saved.\n",
      "Image confusion_petr4.sa_3_4 saved.\n",
      "Image roc_petr4.sa_3_4 saved.\n",
      "Image confusion_petr4.sa_7_4 saved.\n",
      "Image roc_petr4.sa_7_4 saved.\n",
      "Image confusion_petr4.sa_15_4 saved.\n",
      "Image roc_petr4.sa_15_4 saved.\n",
      "Image confusion_petr4.sa_30_4 saved.\n",
      "Image roc_petr4.sa_30_4 saved.\n",
      "Image confusion_petr4.sa_60_4 saved.\n",
      "Image roc_petr4.sa_60_4 saved.\n",
      "Image confusion_vale3.sa_3_5 saved.\n",
      "Image roc_vale3.sa_3_5 saved.\n",
      "Image confusion_vale3.sa_7_5 saved.\n",
      "Image roc_vale3.sa_7_5 saved.\n",
      "Image confusion_vale3.sa_15_5 saved.\n",
      "Image roc_vale3.sa_15_5 saved.\n",
      "Image confusion_vale3.sa_30_5 saved.\n",
      "Image roc_vale3.sa_30_5 saved.\n",
      "Image confusion_vale3.sa_60_5 saved.\n",
      "Image roc_vale3.sa_60_5 saved.\n",
      "Image confusion_itub4.sa_3_5 saved.\n",
      "Image roc_itub4.sa_3_5 saved.\n",
      "Image confusion_itub4.sa_7_5 saved.\n",
      "Image roc_itub4.sa_7_5 saved.\n",
      "Image confusion_itub4.sa_15_5 saved.\n",
      "Image roc_itub4.sa_15_5 saved.\n",
      "Image confusion_itub4.sa_30_5 saved.\n",
      "Image roc_itub4.sa_30_5 saved.\n",
      "Image confusion_itub4.sa_60_5 saved.\n",
      "Image roc_itub4.sa_60_5 saved.\n",
      "Image confusion_bbdc4.sa_3_5 saved.\n",
      "Image roc_bbdc4.sa_3_5 saved.\n",
      "Image confusion_bbdc4.sa_7_5 saved.\n",
      "Image roc_bbdc4.sa_7_5 saved.\n",
      "Image confusion_bbdc4.sa_15_5 saved.\n",
      "Image roc_bbdc4.sa_15_5 saved.\n",
      "Image confusion_bbdc4.sa_30_5 saved.\n",
      "Image roc_bbdc4.sa_30_5 saved.\n",
      "Image confusion_bbdc4.sa_60_5 saved.\n",
      "Image roc_bbdc4.sa_60_5 saved.\n",
      "Image confusion_petr4.sa_3_5 saved.\n",
      "Image roc_petr4.sa_3_5 saved.\n",
      "Image confusion_petr4.sa_7_5 saved.\n",
      "Image roc_petr4.sa_7_5 saved.\n",
      "Image confusion_petr4.sa_15_5 saved.\n",
      "Image roc_petr4.sa_15_5 saved.\n",
      "Image confusion_petr4.sa_30_5 saved.\n",
      "Image roc_petr4.sa_30_5 saved.\n",
      "Image confusion_petr4.sa_60_5 saved.\n",
      "Image roc_petr4.sa_60_5 saved.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for rod in [6, 7, 8]:\n",
    "    \n",
    "    final_results = pd.DataFrame()\n",
    "\n",
    "    for ticker in ['vale3.sa', 'itub4.sa', 'bbdc4.sa', 'petr4.sa']:\n",
    "\n",
    "        df_ticker = pd.read_csv(f'data/processed/{ticker}_processed.csv', encoding='utf8', delimiter=',')\n",
    "        df_ticker['date'] = pd.to_datetime(df_ticker['date'])\n",
    "        df_ticker_target = df_ticker.loc[(df_ticker['date'] >= '2015-01-01')]\n",
    "\n",
    "        for days in [3, 7, 15, 30, 60]:\n",
    "\n",
    "            df_train = generate_label(days, df_ticker_target)\n",
    "            df_train = df_train.set_index('date')\n",
    "\n",
    "            transfor = 'normal'\n",
    "            dir_func = np.log if transfor == 'log' else lambda x:x\n",
    "            inf_func = np.exp if transfor == 'log' else lambda x:x\n",
    "\n",
    "            cols_to_transform = [col for col in df_train.columns if not 'target' in col]\n",
    "            df_train[cols_to_transform] = dir_func(df_train[cols_to_transform])\n",
    "\n",
    "\n",
    "            X = df_train.drop(columns = 'target')\n",
    "            y = df_train['target']\n",
    "            feature_names = X.columns\n",
    "\n",
    "            st_feat = MinMaxScaler()\n",
    "            X = X.sort_index(axis = 1)\n",
    "            X = st_feat.fit_transform(X)\n",
    "\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y)\n",
    "\n",
    "            ### Feature Selection\n",
    "            rf = RandomForestClassifier(n_estimators=400, min_samples_leaf=2, oob_score=True, bootstrap=True, n_jobs=4)\n",
    "            rf.fit(X, y)\n",
    "            \n",
    "            rfe = RFECV(rf, cv=5, scoring=\"neg_mean_squared_error\")\n",
    "            rfe.fit(X_train,y_train)\n",
    "            selected_features = list(np.array(feature_names)[rfe.get_support()])\n",
    "            df_selected = df_train[selected_features + ['target']]\n",
    "\n",
    "            classifiers = [\n",
    "                (\"KNC\", KNeighborsClassifier(n_neighbors = 5, weights = \"distance\", p = 1)),\n",
    "                (\"SVC\", SVC(kernel= \"rbf\", gamma = 3.5, C = 1000)),\n",
    "                (\"MLP\", MLPClassifier(max_iter = 10000, activation = 'tanh', alpha = 0.0001, learning_rate = 'constant')),\n",
    "                (\"RF\", RandomForestClassifier(n_estimators=400, min_samples_leaf=2, oob_score=True, bootstrap=True, n_jobs=4)),\n",
    "                (\"ADA\", AdaBoostClassifier(n_estimators = 1000, base_estimator = DecisionTreeClassifier(max_depth=9, min_samples_leaf = 2)))\n",
    "            ]\n",
    "\n",
    "            X = df_selected.drop(columns = 'target')\n",
    "            y = df_selected['target']\n",
    "            feature_names = X.columns\n",
    "\n",
    "            st_feat = MinMaxScaler()\n",
    "            X = X.sort_index(axis = 1)\n",
    "            X = st_feat.fit_transform(X)\n",
    "\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y)\n",
    "\n",
    "            clf = StackingClassifier(estimators=classifiers, final_estimator = RandomForestClassifier(n_estimators=400, min_samples_leaf=2, oob_score=True, bootstrap=True, n_jobs=4))\n",
    "\n",
    "            clf.fit(X_train, y_train)\n",
    "\n",
    "            fpr, tpr, thresholds = roc_curve(y_test, clf.predict(X_test))\n",
    "\n",
    "            confusion = sns.heatmap(confusion_matrix(y_test, clf.predict(X_test)), annot=True,  fmt='d', cmap='Reds')\n",
    "            confusion.set_title(\"Matriz de Confusão\", fontsize=18)\n",
    "            confusion.set_ylabel(\"Classe Verdadeira\")\n",
    "            confusion.set_xlabel(\"Classe Prevista\")\n",
    "            save_image(img=confusion, name=f'confusion_{ticker}_{days}_{rod}')\n",
    "            plt.clf()\n",
    "\n",
    "            fpr, tpr, thresholds = roc_curve(y_test, clf.predict(X_test))\n",
    "            roc = sns.lineplot(x = fpr, y = tpr)\n",
    "            plt.plot([0,1], [0,1], 'k--')\n",
    "            plt.axis([0, 1, 0, 1])\n",
    "            plt.xlabel('Taxa de Falsos Positivos')\n",
    "            plt.ylabel('Taxa de Verdadeiros Positivos')\n",
    "            plt.title('Curva ROC', fontsize = 14)\n",
    "            save_image(img=roc, name=f'roc_{ticker}_{days}_{rod}')\n",
    "            plt.clf()\n",
    "\n",
    "            dict_results = {'Ação': ticker,\n",
    "                            'Dias': days,\n",
    "                            'Acuracia': accuracy_score(y_test, clf.predict(X_test)),\n",
    "                            'Precisão': precision_score(y_test, clf.predict(X_test)),\n",
    "                            'Recall': recall_score(y_test, clf.predict(X_test)),\n",
    "                            'F1': f1_score(y_test, clf.predict(X_test)),\n",
    "                            'AUC': auc(fpr, tpr),\n",
    "                            'Features': [selected_features]}\n",
    "            \n",
    "            results = pd.DataFrame(dict_results)\n",
    "            \n",
    "            final_results = pd.concat([final_results, results])\n",
    "\n",
    "            final_results.to_excel(f'results_{ticker}_{days}_{rod}.xlsx', index = False)\n",
    "        \n",
    "        final_results.to_excel(f'results_{ticker}_{rod}.xlsx', index = False)\n",
    "\n",
    "    final_results.to_excel(f'results_{rod}.xlsx', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avaliando dados posteriores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker = 'petr4.sa'\n",
    "df_ticker = pd.read_csv(f'data/processed/{ticker}_processed.csv', encoding='utf8', delimiter=',')\n",
    "df_ticker['date'] = pd.to_datetime(df_ticker['date'])\n",
    "df_ticker_target = df_ticker.loc[(df_ticker['date'] >= '2015-01-01') & (df_ticker['date'] <= '2022-09-16')]\n",
    "df_ticker_valid = df_ticker.loc[(df_ticker['date'] >= '2022-09-17') & (df_ticker['date'] <= '2022-11-13')]\n",
    "\n",
    "days = 30\n",
    "df_train = generate_label(days, df_ticker_target)\n",
    "df_train = df_train.set_index('date')\n",
    "\n",
    "df_valid = generate_label(days, df_ticker_valid)\n",
    "df_valid = df_valid.set_index('date')\n",
    "\n",
    "transfor = 'normal'\n",
    "dir_func = np.log if transfor == 'log' else lambda x:x\n",
    "inf_func = np.exp if transfor == 'log' else lambda x:x\n",
    "\n",
    "cols_to_transform = [col for col in df_train.columns if not 'target' in col]\n",
    "df_train[cols_to_transform] = dir_func(df_train[cols_to_transform])\n",
    "\n",
    "cols_to_transform = [col for col in df_valid.columns if not 'target' in col]\n",
    "df_valid[cols_to_transform] = dir_func(df_valid[cols_to_transform])\n",
    "\n",
    "X = df_train.drop(columns = 'target')\n",
    "y = df_train['target']\n",
    "feature_names = X.columns\n",
    "\n",
    "st_feat = MinMaxScaler()\n",
    "X = X.sort_index(axis = 1)\n",
    "st_feat.fit(X)\n",
    "X = st_feat.transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y)\n",
    "\n",
    "### Feature Selection\n",
    "rf = RandomForestClassifier(n_estimators=400, min_samples_leaf=2, oob_score=True, bootstrap=True, n_jobs=4)\n",
    "rf.fit(X, y)\n",
    "  \n",
    "rfe = RFECV(rf, cv=5, scoring=\"neg_mean_squared_error\")\n",
    "rfe.fit(X_train,y_train)\n",
    "selected_features = list(np.array(feature_names)[rfe.get_support()])\n",
    "df_selected = df_train[selected_features + ['target']]\n",
    "\n",
    "df_selected_valid = df_valid[selected_features + ['target']]\n",
    "\n",
    "classifiers = [\n",
    "    (\"KNC\", KNeighborsClassifier(n_neighbors = 5, weights = \"distance\", p = 1)),\n",
    "    (\"SVC\", SVC(kernel= \"rbf\", gamma = 3.5, C = 1000)),\n",
    "    (\"MLP\", MLPClassifier(max_iter = 10000, activation = 'tanh', alpha = 0.0001, learning_rate = 'constant')),\n",
    "    (\"RF\", RandomForestClassifier(n_estimators=400, min_samples_leaf=2, oob_score=True, bootstrap=True, n_jobs=4)),\n",
    "    (\"ADA\", AdaBoostClassifier(n_estimators = 1000, base_estimator = DecisionTreeClassifier(max_depth=9, min_samples_leaf = 2)))\n",
    "]\n",
    "\n",
    "X = df_selected.drop(columns = 'target')\n",
    "y = df_selected['target']\n",
    "feature_names = X.columns\n",
    "\n",
    "x_valid = df_selected_valid.drop(columns = 'target')\n",
    "y_valid = df_selected_valid['target']\n",
    "\n",
    "st_feat = MinMaxScaler()\n",
    "X = X.sort_index(axis = 1)\n",
    "st_feat.fit(X)\n",
    "X = st_feat.transform(X)\n",
    "\n",
    "x_valid = x_valid.sort_index(axis = 1)\n",
    "x_valid = st_feat.transform(x_valid)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y)\n",
    "\n",
    "clf = StackingClassifier(estimators=classifiers, final_estimator = RandomForestClassifier(n_estimators=400, min_samples_leaf=2, oob_score=True, bootstrap=True, n_jobs=4))\n",
    "\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_valid, clf.predict(x_valid))\n",
    "\n",
    "confusion = sns.heatmap(confusion_matrix(y_valid, clf.predict(x_valid)), annot=True,  fmt='d', cmap='Reds')\n",
    "confusion.set_title(\"Matriz de Confusão\", fontsize=18)\n",
    "confusion.set_ylabel(\"Classe Verdadeira\")\n",
    "confusion.set_xlabel(\"Classe Prevista\")\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_valid, clf.predict(x_valid))\n",
    "roc = sns.lineplot(x = fpr, y = tpr)\n",
    "plt.plot([0,1], [0,1], 'k--')\n",
    "plt.axis([0, 1, 0, 1])\n",
    "plt.xlabel('Taxa de Falsos Positivos')\n",
    "plt.ylabel('Taxa de Verdadeiros Positivos')\n",
    "plt.title('Curva ROC', fontsize = 14)\n",
    "\n",
    "dict_results = {'Ação': ticker,\n",
    "                'Dias': days,\n",
    "                'Acuracia': accuracy_score(y_valid, clf.predict(x_valid)),\n",
    "                'Precisão': precision_score(y_valid, clf.predict(x_valid)),\n",
    "                'Recall': recall_score(y_valid, clf.predict(x_valid)),\n",
    "                'F1': f1_score(y_valid, clf.predict(x_valid)),\n",
    "                'AUC': auc(fpr, tpr),\n",
    "                'Features': [selected_features]}\n",
    "\n",
    "results = pd.DataFrame(dict_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Guilherme\\anaconda3\\envs\\tcc-env\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:999: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "c:\\Users\\Guilherme\\anaconda3\\envs\\tcc-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Guilherme\\anaconda3\\envs\\tcc-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Guilherme\\anaconda3\\envs\\tcc-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "c:\\Users\\Guilherme\\anaconda3\\envs\\tcc-env\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:999: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "c:\\Users\\Guilherme\\anaconda3\\envs\\tcc-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Guilherme\\anaconda3\\envs\\tcc-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Guilherme\\anaconda3\\envs\\tcc-env\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:999: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "c:\\Users\\Guilherme\\anaconda3\\envs\\tcc-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Guilherme\\anaconda3\\envs\\tcc-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Guilherme\\anaconda3\\envs\\tcc-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "c:\\Users\\Guilherme\\anaconda3\\envs\\tcc-env\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:999: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "c:\\Users\\Guilherme\\anaconda3\\envs\\tcc-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Guilherme\\anaconda3\\envs\\tcc-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Guilherme\\anaconda3\\envs\\tcc-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "c:\\Users\\Guilherme\\anaconda3\\envs\\tcc-env\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:999: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "c:\\Users\\Guilherme\\anaconda3\\envs\\tcc-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Guilherme\\anaconda3\\envs\\tcc-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Guilherme\\anaconda3\\envs\\tcc-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    }
   ],
   "source": [
    "for rod in [1, 2, 3, 4, 5]:\n",
    "    \n",
    "    final_results = pd.DataFrame()\n",
    "    final_results_valid = pd.DataFrame()\n",
    "\n",
    "    for ticker in ['vale3.sa', 'itub4.sa', 'bbdc4.sa', 'petr4.sa']:\n",
    "\n",
    "        df_ticker = pd.read_csv(f'data/processed/{ticker}_processed.csv', encoding='utf8', delimiter=',')\n",
    "        df_ticker['date'] = pd.to_datetime(df_ticker['date'])\n",
    "        df_ticker_target = df_ticker.loc[(df_ticker['date'] >= '2015-01-01') & (df_ticker['date'] < '2022-08-01')]\n",
    "        df_ticker_valid = df_ticker.loc[(df_ticker['date'] >= '2022-08-01') & (df_ticker['date'] <= '2022-11-13')]\n",
    "        \n",
    "        for days in [3, 7, 15, 30, 60]:\n",
    "\n",
    "            df_train = generate_label(days, df_ticker_target)\n",
    "            df_train = df_train.set_index('date')\n",
    "\n",
    "            df_valid = generate_label(days, df_ticker_valid)\n",
    "            df_valid = df_valid.set_index('date')\n",
    "\n",
    "            transfor = 'normal'\n",
    "            dir_func = np.log if transfor == 'log' else lambda x:x\n",
    "            inf_func = np.exp if transfor == 'log' else lambda x:x\n",
    "\n",
    "            cols_to_transform = [col for col in df_train.columns if not 'target' in col]\n",
    "            df_train[cols_to_transform] = dir_func(df_train[cols_to_transform])\n",
    "\n",
    "            cols_to_transform = [col for col in df_valid.columns if not 'target' in col]\n",
    "            df_valid[cols_to_transform] = dir_func(df_valid[cols_to_transform])\n",
    "\n",
    "            X = df_train.drop(columns = 'target')\n",
    "            y = df_train['target']\n",
    "            feature_names = X.columns\n",
    "\n",
    "            st_feat = MinMaxScaler()\n",
    "            X = X.sort_index(axis = 1)\n",
    "            X = st_feat.fit_transform(X)\n",
    "\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y)\n",
    "\n",
    "            ### Feature Selection\n",
    "            rf = RandomForestClassifier(n_estimators=400, min_samples_leaf=2, oob_score=True, bootstrap=True, n_jobs=4)\n",
    "            rf.fit(X, y)\n",
    "            \n",
    "            rfe = RFECV(rf, cv=5, scoring=\"neg_mean_squared_error\")\n",
    "            rfe.fit(X_train,y_train)\n",
    "            selected_features = list(np.array(feature_names)[rfe.get_support()])\n",
    "            df_selected = df_train[selected_features + ['target']]\n",
    "            df_selected_valid = df_valid[selected_features + ['target']]\n",
    "\n",
    "            classifiers = [\n",
    "            (\"KNC\", KNeighborsClassifier(n_neighbors = 5, weights = \"distance\", p = 1)),\n",
    "            (\"SVC\", SVC(kernel= \"rbf\", gamma = 3.5, C = 1000)),\n",
    "            (\"MLP\", MLPClassifier(max_iter = 10000, activation = 'tanh', alpha = 0.0001, learning_rate = 'constant')),\n",
    "            (\"RF\", RandomForestClassifier(n_estimators=400, min_samples_leaf=2, oob_score=True, bootstrap=True, n_jobs=4)),\n",
    "            (\"ADA\", AdaBoostClassifier(n_estimators = 1000, base_estimator = DecisionTreeClassifier(max_depth=9, min_samples_leaf = 2)))\n",
    "            ]\n",
    "\n",
    "            X = df_selected.drop(columns = 'target')\n",
    "            y = df_selected['target']\n",
    "            feature_names = X.columns\n",
    "\n",
    "            x_valid = df_selected_valid.drop(columns = 'target')\n",
    "            y_valid = df_selected_valid['target']\n",
    "\n",
    "            st_feat = MinMaxScaler()\n",
    "            X = X.sort_index(axis = 1)\n",
    "            st_feat.fit(X)\n",
    "            X = st_feat.transform(X)\n",
    "\n",
    "            x_valid = x_valid.sort_index(axis = 1)\n",
    "            x_valid = st_feat.transform(x_valid)\n",
    "\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y)\n",
    "\n",
    "            clf = StackingClassifier(estimators=classifiers, final_estimator = RandomForestClassifier(n_estimators=400, min_samples_leaf=2, oob_score=True, bootstrap=True, n_jobs=4))\n",
    "\n",
    "            clf.fit(X_train, y_train)\n",
    "\n",
    "            fpr, tpr, thresholds = roc_curve(y_test, clf.predict(X_test))\n",
    "\n",
    "            dict_results = {'Ação': ticker,\n",
    "                            'Dias': days,\n",
    "                            'Acuracia': accuracy_score(y_test, clf.predict(X_test)),\n",
    "                            'Precisão': precision_score(y_test, clf.predict(X_test)),\n",
    "                            'Recall': recall_score(y_test, clf.predict(X_test)),\n",
    "                            'F1': f1_score(y_test, clf.predict(X_test)),\n",
    "                            'AUC': auc(fpr, tpr),\n",
    "                            'Features': [selected_features]}\n",
    "            \n",
    "            results = pd.DataFrame(dict_results)\n",
    "            \n",
    "            final_results = pd.concat([final_results, results])\n",
    "\n",
    "            fpr_valid, tpr_valid, thresholds_valid = roc_curve(y_valid, clf.predict(x_valid))\n",
    "\n",
    "            dict_results_valid = {'Ação': ticker,\n",
    "                                  'Dias': days,\n",
    "                                  'Acuracia': accuracy_score(y_valid, clf.predict(x_valid)),\n",
    "                                  'Precisão': precision_score(y_valid, clf.predict(x_valid)),\n",
    "                                  'Recall': recall_score(y_valid, clf.predict(x_valid)),\n",
    "                                  'F1': f1_score(y_valid, clf.predict(x_valid)),\n",
    "                                  'AUC': auc(fpr_valid, tpr_valid),\n",
    "                                  'Features': [selected_features]}\n",
    "            \n",
    "            results_valid = pd.DataFrame(dict_results_valid)\n",
    "            \n",
    "            final_results_valid = pd.concat([final_results_valid, results_valid])\n",
    "\n",
    "            labels = y_valid.to_frame()\n",
    "            teste = clf.predict(x_valid)\n",
    "            se = pd.Series(teste)\n",
    "            labels[f'predicted_{rod}'] = se.values\n",
    "\n",
    "            final_results.to_excel(f'results_{ticker}_{days}_{rod}.xlsx', index = False)\n",
    "            final_results_valid.to_excel(f'results_{ticker}_{days}_{rod}_valid.xlsx', index = False)\n",
    "            \n",
    "            labels.to_excel(f'labels_{ticker}_{days}_{rod}_valid.xlsx', index = False)\n",
    "\n",
    "        final_results.to_excel(f'results_{ticker}_{rod}.xlsx', index = False)\n",
    "        final_results_valid.to_excel(f'results_{ticker}_{rod}_valid.xlsx', index = False)\n",
    "\n",
    "    final_results.to_excel(f'results_{rod}.xlsx', index = False)\n",
    "    final_results_valid.to_excel(f'results_{rod}_valid.xlsx', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Guilherme\\anaconda3\\envs\\tcc-env\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:999: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "c:\\Users\\Guilherme\\anaconda3\\envs\\tcc-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Guilherme\\anaconda3\\envs\\tcc-env\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:999: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "c:\\Users\\Guilherme\\anaconda3\\envs\\tcc-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Guilherme\\anaconda3\\envs\\tcc-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Guilherme\\anaconda3\\envs\\tcc-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "c:\\Users\\Guilherme\\anaconda3\\envs\\tcc-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Guilherme\\anaconda3\\envs\\tcc-env\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:999: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "c:\\Users\\Guilherme\\anaconda3\\envs\\tcc-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Guilherme\\anaconda3\\envs\\tcc-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Guilherme\\anaconda3\\envs\\tcc-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "c:\\Users\\Guilherme\\anaconda3\\envs\\tcc-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Guilherme\\anaconda3\\envs\\tcc-env\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:999: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "c:\\Users\\Guilherme\\anaconda3\\envs\\tcc-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Guilherme\\anaconda3\\envs\\tcc-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Guilherme\\anaconda3\\envs\\tcc-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "c:\\Users\\Guilherme\\anaconda3\\envs\\tcc-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Guilherme\\anaconda3\\envs\\tcc-env\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:999: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "c:\\Users\\Guilherme\\anaconda3\\envs\\tcc-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mO Kernel falhou ao executar o código na célula atual ou em uma célula anterior. Examine o código nas células para identificar uma possível causa da falha. Clique <a href=\"https://aka.ms/vscodeJupyterKernelCrash\">aqui</a> para obter mais informações. Consulte o <a href='command:jupyter.viewOutput'>log</a> do Jupyter para obter mais detalhes."
     ]
    }
   ],
   "source": [
    "for rod in [6, 7, 8, 9, 10]:\n",
    "    \n",
    "    final_results = pd.DataFrame()\n",
    "    final_results_valid = pd.DataFrame()\n",
    "\n",
    "    for ticker in ['vale3.sa', 'itub4.sa', 'bbdc4.sa', 'petr4.sa']:\n",
    "\n",
    "        df_ticker = pd.read_csv(f'data/processed/{ticker}_processed.csv', encoding='utf8', delimiter=',')\n",
    "        df_ticker['date'] = pd.to_datetime(df_ticker['date'])\n",
    "        df_ticker_target = df_ticker.loc[(df_ticker['date'] >= '2015-01-01') & (df_ticker['date'] < '2022-08-01')]\n",
    "        df_ticker_valid = df_ticker.loc[(df_ticker['date'] >= '2022-08-01') & (df_ticker['date'] <= '2022-11-13')]\n",
    "        \n",
    "        for days in [3, 7, 15, 30, 60]:\n",
    "\n",
    "            df_train = generate_label(days, df_ticker_target)\n",
    "            df_train = df_train.set_index('date')\n",
    "\n",
    "            df_valid = generate_label(days, df_ticker_valid)\n",
    "            df_valid = df_valid.set_index('date')\n",
    "\n",
    "            transfor = 'normal'\n",
    "            dir_func = np.log if transfor == 'log' else lambda x:x\n",
    "            inf_func = np.exp if transfor == 'log' else lambda x:x\n",
    "\n",
    "            cols_to_transform = [col for col in df_train.columns if not 'target' in col]\n",
    "            df_train[cols_to_transform] = dir_func(df_train[cols_to_transform])\n",
    "\n",
    "            cols_to_transform = [col for col in df_valid.columns if not 'target' in col]\n",
    "            df_valid[cols_to_transform] = dir_func(df_valid[cols_to_transform])\n",
    "\n",
    "            X = df_train.drop(columns = 'target')\n",
    "            y = df_train['target']\n",
    "            feature_names = X.columns\n",
    "\n",
    "            st_feat = MinMaxScaler()\n",
    "            X = X.sort_index(axis = 1)\n",
    "            X = st_feat.fit_transform(X)\n",
    "\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y)\n",
    "\n",
    "            ### Feature Selection\n",
    "            rf = RandomForestClassifier(n_estimators=400, min_samples_leaf=2, oob_score=True, bootstrap=True, n_jobs=4)\n",
    "            rf.fit(X, y)\n",
    "            \n",
    "            rfe = RFECV(rf, cv=5, scoring=\"neg_mean_squared_error\")\n",
    "            rfe.fit(X_train,y_train)\n",
    "            selected_features = list(np.array(feature_names)[rfe.get_support()])\n",
    "            df_selected = df_train[selected_features + ['target']]\n",
    "            df_selected_valid = df_valid[selected_features + ['target']]\n",
    "\n",
    "            classifiers = [\n",
    "            (\"KNC\", KNeighborsClassifier(n_neighbors = 5, weights = \"distance\", p = 1)),\n",
    "            (\"SVC\", SVC(kernel= \"rbf\", gamma = 3.5, C = 1000)),\n",
    "            (\"MLP\", MLPClassifier(max_iter = 10000, activation = 'tanh', alpha = 0.0001, learning_rate = 'constant')),\n",
    "            (\"RF\", RandomForestClassifier(n_estimators=400, min_samples_leaf=2, oob_score=True, bootstrap=True, n_jobs=4)),\n",
    "            (\"ADA\", AdaBoostClassifier(n_estimators = 1000, base_estimator = DecisionTreeClassifier(max_depth=9, min_samples_leaf = 2)))\n",
    "            ]\n",
    "\n",
    "            X = df_selected.drop(columns = 'target')\n",
    "            y = df_selected['target']\n",
    "            feature_names = X.columns\n",
    "\n",
    "            x_valid = df_selected_valid.drop(columns = 'target')\n",
    "            y_valid = df_selected_valid['target']\n",
    "\n",
    "            st_feat = MinMaxScaler()\n",
    "            X = X.sort_index(axis = 1)\n",
    "            st_feat.fit(X)\n",
    "            X = st_feat.transform(X)\n",
    "\n",
    "            x_valid = x_valid.sort_index(axis = 1)\n",
    "            x_valid = st_feat.transform(x_valid)\n",
    "\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y)\n",
    "\n",
    "            clf = StackingClassifier(estimators=classifiers, final_estimator = RandomForestClassifier(n_estimators=400, min_samples_leaf=2, oob_score=True, bootstrap=True, n_jobs=4))\n",
    "\n",
    "            clf.fit(X_train, y_train)\n",
    "\n",
    "            fpr, tpr, thresholds = roc_curve(y_test, clf.predict(X_test))\n",
    "\n",
    "            dict_results = {'Ação': ticker,\n",
    "                            'Dias': days,\n",
    "                            'Acuracia': accuracy_score(y_test, clf.predict(X_test)),\n",
    "                            'Precisão': precision_score(y_test, clf.predict(X_test)),\n",
    "                            'Recall': recall_score(y_test, clf.predict(X_test)),\n",
    "                            'F1': f1_score(y_test, clf.predict(X_test)),\n",
    "                            'AUC': auc(fpr, tpr),\n",
    "                            'Features': [selected_features]}\n",
    "            \n",
    "            results = pd.DataFrame(dict_results)\n",
    "            \n",
    "            final_results = pd.concat([final_results, results])\n",
    "\n",
    "            fpr_valid, tpr_valid, thresholds_valid = roc_curve(y_valid, clf.predict(x_valid))\n",
    "\n",
    "            dict_results_valid = {'Ação': ticker,\n",
    "                                  'Dias': days,\n",
    "                                  'Acuracia': accuracy_score(y_valid, clf.predict(x_valid)),\n",
    "                                  'Precisão': precision_score(y_valid, clf.predict(x_valid)),\n",
    "                                  'Recall': recall_score(y_valid, clf.predict(x_valid)),\n",
    "                                  'F1': f1_score(y_valid, clf.predict(x_valid)),\n",
    "                                  'AUC': auc(fpr_valid, tpr_valid),\n",
    "                                  'Features': [selected_features]}\n",
    "            \n",
    "            results_valid = pd.DataFrame(dict_results_valid)\n",
    "            \n",
    "            final_results_valid = pd.concat([final_results_valid, results_valid])\n",
    "\n",
    "            labels = y_valid.to_frame()\n",
    "            teste = clf.predict(x_valid)\n",
    "            se = pd.Series(teste)\n",
    "            labels[f'predicted_{rod}'] = se.values\n",
    "\n",
    "            final_results.to_excel(f'results_{ticker}_{days}_{rod}.xlsx', index = False)\n",
    "            final_results_valid.to_excel(f'results_{ticker}_{days}_{rod}_valid.xlsx', index = False)\n",
    "            \n",
    "            labels.to_excel(f'labels_{ticker}_{days}_{rod}_valid.xlsx', index = False)\n",
    "\n",
    "        final_results.to_excel(f'results_{ticker}_{rod}.xlsx', index = False)\n",
    "        final_results_valid.to_excel(f'results_{ticker}_{rod}_valid.xlsx', index = False)\n",
    "\n",
    "    final_results.to_excel(f'results_{rod}.xlsx', index = False)\n",
    "    final_results_valid.to_excel(f'results_{rod}_valid.xlsx', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "599cece8842e6c1d97d182baa7f05812114be06ab240db449e2045f3a1c361b6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
